# Medallion Architecture Pipeline (Airflow + dbt + DuckDB)

Integrantes:

* **Mat√≠as Caccia**
* **Sebasti√°n Mesch Henriques**

Este proyecto implementa un pipeline de datos siguiendo la **arquitectura Medallion (Bronze ‚Üí Silver ‚Üí Gold)** utilizando:

* **Airflow** como orquestador
* **Pandas** para la etapa Bronze
* **dbt + DuckDB** para modelado Silver y Gold
* **Tests personalizados** de calidad de datos
* **Reportes autom√°ticos de Data Quality (DQ)**

El objetivo es demostrar un pipeline moderno, limpio y escalable que aplica pr√°cticas reales de ingenier√≠a de datos:

* Buenas pr√°cticas de ingesti√≥n
* Normalizaci√≥n y validaci√≥n robusta en Bronze
* Modelado en dbt en capas Silver/Gold
* Data Quality s√≥lido con tests gen√©ricos y singulares
* Observabilidad y trazabilidad completa del pipeline

---

# Estructura del proyecto

```
‚îú‚îÄ‚îÄ dags/
‚îÇ   ‚îî‚îÄ‚îÄ medallion_medallion_dag.py        <- DAG completo Bronze/Silver/Gold
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                              <- Archivos CSV crudos
‚îÇ   ‚îú‚îÄ‚îÄ clean/                            <- Parquet Bronze
‚îÇ   ‚îî‚îÄ‚îÄ quality/                          <- Resultados Gold (DQ)
‚îú‚îÄ‚îÄ dbt/
‚îÇ   ‚îú‚îÄ‚îÄ dbt_project.yml
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ staging/                      <- stg_transactions.sql + schema.yml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ marts/                        <- fct_customer_transactions.sql + schema.yml
‚îÇ   ‚îî‚îÄ‚îÄ tests/                            <- Tests gen√©ricos y singulares (Silver/Gold)
‚îú‚îÄ‚îÄ include/
‚îÇ   ‚îî‚îÄ‚îÄ transformations.py                <- Limpieza Bronze robusta
‚îú‚îÄ‚îÄ profiles/
‚îÇ   ‚îî‚îÄ‚îÄ profiles.yml                      <- Perfil DuckDB para dbt
‚îú‚îÄ‚îÄ warehouse/
‚îÇ   ‚îî‚îÄ‚îÄ medallion.duckdb                  <- Base creada en runtime
‚îî‚îÄ‚îÄ requirements.txt
```

---

# üß± Arquitectura Medallion Implementada

## ü•â BRONZE ‚Äî Limpieza m√≠nima pero confiable con Pandas

Airflow ejecuta:

```python
clean_daily_transactions(execution_date, RAW_DIR, CLEAN_DIR)
```

### Mejoras implementadas en Bronze

‚úî Validaci√≥n de columnas requeridas
‚úî Normalizaci√≥n de `amount` ‚Üí num√©rico robusto
‚úî Normalizaci√≥n de `status` ‚Üí lowercase + mapping estricto
‚úî Parsing seguro de timestamps
‚úî Eliminaci√≥n de fechas futuras
‚úî Eliminaci√≥n de duplicados
‚úî Validaci√≥n de que existan filas v√°lidas
‚úî Escritura en Parquet eficiente y est√°ndar

Salida:

```
data/clean/transactions_<ds>_clean.parquet
```

## ü•à SILVER ‚Äî Modelado con dbt

Airflow ejecuta:

```
dbt run
```

Silver produce un modelo limpio, tipado y listo para an√°lisis:

* `stg_transactions.sql`
* Derivaci√≥n de `transaction_date`
* Cast de tipos seg√∫n `schema.yml`
* Validaciones complejas a nivel de dominio

### Tests implementados en Silver y su raz√≥n de ser

A continuaci√≥n, se describen todos los tests incluidos, **por qu√© existen**, y **cu√°ndo fallar√≠an** en un sistema real.

#### 1. `not_null`

Asegura que columnas esenciales no est√©n vac√≠as.

**Fallar√≠a si:**

* El archivo crudo viene truncado
* El upstream omite campos
* Se rompe el mapeo de status o amounts

#### 2. `unique` (transaction_id)

Cada transacci√≥n debe ser √∫nica.

**Fallar√≠a si:**

* El proveedor env√≠a duplicados
* Se concatenan archivos accidentalmente
* El sistema upstream reenv√≠a transacciones

#### 3. `non_negative` (amount)

Un monto nunca debe ser negativo.

**Fallar√≠a si:**

* Se invierte el signo por error
* Se registran reversas mal representadas
* Hay fallas del ETL upstream

#### 4. `accepted_status`

S√≥lo se aceptan:

```
completed | pending | failed
```

**Fallar√≠a si:**

* Aparece un nuevo estado no documentado
* Existen inconsistencias (Completed, completed , UNKNOWN)
* Hay problemas de input manual

#### 5. `valid_timestamp`

Verifica que `transaction_ts` sea un timestamp v√°lido.

**Fallar√≠a si:**

* Aparecen fechas inv√°lidas (‚Äú2025/13/99‚Äù)
* Hay strings corruptas
* El upstream env√≠a formatos distintos

#### 6. `not_in_future`

Protege contra timestamps futuros.

**Fallar√≠a si:**

* El reloj del upstream est√° adelantado
* Existen datos simulados colados en producci√≥n
* Hay errores en la conversi√≥n de zona horaria

#### 7. `unique_transaction_id`

Segunda barrera contra duplicados, valida l√≥gica de negocio.

**Fallar√≠a si:**

* Un d√≠a se carga dos veces el mismo archivo
* Se incorporan filas repetidas despu√©s del Bronze

#### 8. `amount_not_outlier`

Detecta outliers usando IQR.

**Fallar√≠a si:**

* Hay transacciones fraudulentas
* Hay errores manuales de carga
* Se recibe ‚Äú5000000‚Äù por error humano o de sistema


#### 9. `no_duplicate_rows`

Evita duplicados completos de todas las columnas.

**Fallar√≠a si:**

* Se adjunta el mismo dataset dos veces
* Hay un join mal aplicado en Bronze
* Pandas concatena archivos sin cuidado

## ü•á GOLD ‚Äî M√©tricas finales + Validaci√≥n avanzada

Airflow ejecuta:

```
dbt test
```

El modelo:

```
fct_customer_transactions.sql
```

Produce:

* `transaction_count`
* `total_amount_completed`
* `total_amount_all`
* `first_transaction_ts`
* `last_transaction_ts`

### üß™ Tests GOLD y su valor anal√≠tico

#### 1. `transaction_count_positive`

Cada cliente debe tener al menos una transacci√≥n.

**Fallar√≠a si:**

* El join Silver‚ÜíGold se rompe
* Se filtran filas accidentalmente
* Se incorporan clientes sin informaci√≥n factual

---

#### 2. `total_amount_non_negative`

Asegura que las sumas nunca sean negativas.

**Fallar√≠a si:**

* Escap√≥ un valor negativo desde Silver
* Las agregaciones est√°n mal definidas
* Se resta accidentalmente en vez de sumar

---

#### 3. `customer_exists_in_silver`

Valida integridad referencial.

**Fallar√≠a si:**

* Hay clientes agregados sin base factual
* Se rompe el join
* Hay llaves mal tipadas

---

#### 4. `valid_transaction_range`

Garantiza consistencia temporal:

```
first_transaction_ts <= last_transaction_ts
```

**Fallar√≠a si:**

* Existen timestamps corruptos
* Alg√∫n cast fall√≥
* Ordenamiento mal aplicado en el modelado

---

#### 5. `unique_customer_rows`

Cada cliente debe aparecer una sola vez.

**Fallar√≠a si:**

* Se agrupa incorrectamente
* Existen duplicados en la l√≥gica Gold
* Se mezclan dimensiones con hechos

### üìÑ Reportes GOLD de Data Quality

La tarea `gold_dbt_test()` genera:

```
data/quality/dq_results_<ds>.json
```

Incluye:

* Estado global (`passed` / `failed`)
* Duraci√≥n de la corrida
* stdout y stderr de dbt
* Existencia del warehouse
* Resumen completo para auditor√≠a

---

# Instalaci√≥n

```bash
python -m venv .venv
source .venv/bin/activate
pip install --upgrade pip
pip install -r requirements.txt
```

---

# Configuraci√≥n de entorno

```bash
export AIRFLOW_HOME=$(pwd)/airflow_home
export DBT_PROFILES_DIR=$(pwd)/profiles
export DUCKDB_PATH=$(pwd)/warehouse/medallion.duckdb
export AIRFLOW__CORE__DAGS_FOLDER=$(pwd)/dags
export AIRFLOW__CORE__LOAD_EXAMPLES=False
```

---

# Inicializar Airflow

```bash
airflow standalone
```

---

# Ejecutar el DAG

1. Colocar un archivo CSV:

```
data/raw/transactions_YYYYMMDD.csv
```

2. Ejecutar:

```bash
airflow dags trigger medallion_pipeline --run-id manual_$(date +%s)
```

---

# Observabilidad por capa

## Bronze

```
duckdb -c "
  select * from read_parquet('data/clean/transactions_<ds>_clean.parquet')
  limit 5;
"
```

## Silver

```
duckdb warehouse/medallion.duckdb -c ".tables"
duckdb warehouse/medallion.duckdb -c "select * from stg_transactions limit 10;"
```

## Gold

```
cat data/quality/dq_results_<ds>.json | jq
```

---

# Ejecutar dbt manualmente

```bash
cd dbt
dbt run
DBT_PROFILES_DIR=../profiles dbt test
```

---

# Conclusi√≥n: Escalabilidad y propuesta arquitect√≥nica

Este pipeline es **perfecto para entornos educativos, prototipos y equipos peque√±os**, pero su dise√±o tambi√©n permite visualizar claramente el camino de evoluci√≥n hacia un sistema de nivel industria.

## ‚úî L√≠mites del dise√±o actual

| Componente         | Limitaci√≥n                            |
| ------------------ | ------------------------------------- |
| Pandas             | No escala horizontalmente             |
| Parquet local      | No soporta concurrencia ni versionado |
| DuckDB             | No distribuido, memoria local         |
| Airflow standalone | No altamente disponible               |

---

# Evoluci√≥n

## 1. Migraci√≥n del almacenamiento

Del local a la nube:

* Amazon S3
* GCS
* Azure Blob

Incluye versionado, gobernanza y escalabilidad.

---

## 2. Migraci√≥n del warehouse

De DuckDB a sistemas distribuidos:

* BigQuery
* Snowflake
* Redshift Serverless
* Databricks + Delta Lake

Beneficios:

* Escalabilidad autom√°tica
* Costos optimizados
* Gran concurrencia en consultas

---

# Casos concretos que justificar√≠an migrar

* Retail procesando **millones de transacciones diarias**
* Empresas que requieren **auditor√≠a estricta y versionado**
* Equipos de BI con decenas de usuarios simult√°neos
* Casos de Machine Learning donde se requieren a√±os de hist√≥rico

---

Este pipeline implementa un ejemplo s√≥lido, profesional y completamente funcional de arquitectura Medallion moderna, integrando:

* Airflow
* dbt
* DuckDB
* Validaciones Silver y Gold avanzadas
* Orquestaci√≥n y observabilidad
* Dise√±o modular y extensible

Adem√°s, muestra c√≥mo este dise√±o puede evolucionar hacia arquitecturas empresariales de gran escala sin reescribir la l√≥gica esencial del negocio.